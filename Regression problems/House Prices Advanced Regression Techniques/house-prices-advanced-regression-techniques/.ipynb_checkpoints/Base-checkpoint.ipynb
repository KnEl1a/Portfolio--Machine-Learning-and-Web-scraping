{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "integrated-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I learned a lot from the book \"feature_engineering_bookcamp\" , and I mod. the code in cells below for regression case\n",
    "# https://github.com/sinanuozdemir/feature_engineering_bookcamp/blob/main/notebooks/Base.ipynb\n",
    "\n",
    "# seed our random values for reproducible code\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc33d88-e6e1-47b8-8ab7-b470d5011ce4",
   "metadata": {},
   "source": [
    "# Base Lines - para problemas de \"Classificación\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "direct-rating",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cla_simple_grid_search(x_train, y_train, x_test, y_test, feature_engineering_pipeline):\n",
    "    ''' \n",
    "    simple helper function to grid search an ExtraTreesClassifier model and \n",
    "    print out a classification report for the best param set.\n",
    "    Best here is defined as having the best cross-validated accuracy on the training set\n",
    "    '''\n",
    "    \n",
    "    params = {  # some simple parameters to grid search\n",
    "        'max_depth': [10, None],\n",
    "        'n_estimators': [10, 50, 100, 500],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    }\n",
    "\n",
    "    base_model = ExtraTreesClassifier()\n",
    "\n",
    "    model_grid_search = GridSearchCV(base_model, param_grid=params, cv=3)\n",
    "    start_time = time.time()  # capture the start time\n",
    "    if feature_engineering_pipeline:  # fit FE pipeline to training data and use it to transform test data\n",
    "        parsed_x_train = feature_engineering_pipeline.fit_transform(x_train, y_train)\n",
    "        parsed_x_test = feature_engineering_pipeline.transform(x_test)\n",
    "    else:\n",
    "        parsed_x_train = x_train\n",
    "        parsed_x_test = x_test\n",
    "\n",
    "    parse_time = time.time()\n",
    "    print(f\"Parsing took {(parse_time - start_time):.2f} seconds\")\n",
    "\n",
    "    model_grid_search.fit(parsed_x_train, y_train)\n",
    "    fit_time = time.time()\n",
    "    print(f\"Training took {(fit_time - start_time):.2f} seconds\")\n",
    "\n",
    "    best_model = model_grid_search.best_estimator_\n",
    "\n",
    "    print(classification_report(y_true=y_test, y_pred=best_model.predict(parsed_x_test)))\n",
    "    end_time = time.time()\n",
    "    print(f\"Overall took {(end_time - start_time):.2f} seconds\")\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "logical-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cla_advanced_grid_search(x_train, y_train, x_test, y_test, ml_pipeline, params, cv=3, include_probas=False, is_regression=False):\n",
    "    ''' \n",
    "    This helper function will grid search a machine learning pipeline with feature engineering included\n",
    "    and print out a classification report for the best param set. \n",
    "    Best here is defined as having the best cross-validated accuracy on the training set\n",
    "    '''\n",
    "    \n",
    "    model_grid_search = GridSearchCV(ml_pipeline, param_grid=params, cv=cv, error_score=-1)\n",
    "    start_time = time.time()  # capture the start time\n",
    "\n",
    "    model_grid_search.fit(x_train, y_train)\n",
    "\n",
    "    best_model = model_grid_search.best_estimator_\n",
    "    \n",
    "    y_preds = best_model.predict(x_test)\n",
    "    \n",
    "    if is_regression:\n",
    "        rmse = np.sqrt(mean_squared_error(y_pred=y_preds, y_true=test_set['pct_change_eod']))\n",
    "        print(f'RMSE: {rmse:.5f}')\n",
    "    else:\n",
    "        print(classification_report(y_true=y_test, y_pred=y_preds))\n",
    "    print(f'Best params: {model_grid_search.best_params_}')\n",
    "    end_time = time.time()\n",
    "    print(f\"Overall took {(end_time - start_time):.2f} seconds\")\n",
    "    \n",
    "    if include_probas:\n",
    "        y_probas = best_model.predict_proba(x_test).max(axis=1)\n",
    "        return best_model, y_preds, y_probas\n",
    "    \n",
    "    return best_model, y_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b413d1-72b2-4f6e-b97d-ff4e40120fab",
   "metadata": {},
   "source": [
    "# Base Lines - para problemas de \"Regresión\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16d5c228-4855-4a06-967b-956b01aa1405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_log_error\n",
    "import time\n",
    "\n",
    "def simple_grid_search_regressor(x_train, y_train, x_test, y_test, feature_engineering_pipeline=None):\n",
    "    '''\n",
    "    Helper function to perform grid search with an LGBM regressor and \n",
    "    print out the Mean Squared Error (MSE) for the best parameter set.\n",
    "    Best here is defined as having the lowest cross-validated error on the training set.\n",
    "    '''\n",
    "    \n",
    "    params = {  # some simple parameters to grid search\n",
    "        'max_depth': [10, None],\n",
    "        'n_estimators': [10, 50, 100, 500],\n",
    "        'objective': ['regression']  # for regression\n",
    "    }\n",
    "\n",
    "    base_model = LGBMRegressor(\n",
    "    n_jobs=-1,          # Utiliza todos los núcleos disponibles\n",
    "    verbose=-1          # Silencia la salida del modelo\n",
    ")\n",
    "\n",
    "    model_grid_search = GridSearchCV(\n",
    "        base_model,\n",
    "        param_grid=params,\n",
    "        cv=3,\n",
    "        verbose=0,  # Silenciar la salida\n",
    "        n_jobs=-1   # Usar todos los núcleos del CPU\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()  # Capture the start time\n",
    "\n",
    "    if feature_engineering_pipeline:  # Fit FE pipeline to training data and use it to transform test data\n",
    "        parsed_x_train = feature_engineering_pipeline.fit_transform(x_train, y_train)\n",
    "        parsed_x_test = feature_engineering_pipeline.transform(x_test)\n",
    "    else:\n",
    "        parsed_x_train = x_train\n",
    "        parsed_x_test = x_test\n",
    "\n",
    "    parse_time = time.time()\n",
    "    \n",
    "    model_grid_search.fit(parsed_x_train, y_train)\n",
    "    fit_time = time.time()\n",
    "\n",
    "    best_model = model_grid_search.best_estimator_\n",
    "\n",
    "    # Predict on the test set and calculate MSE\n",
    "    y_pred = best_model.predict(parsed_x_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "     # Calculate RMSLE\n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_test, y_pred))\n",
    "    \n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Overall took {(end_time - start_time):.2f} seconds\")\n",
    "    print(\"MSE: \", mse)\n",
    "    print(\"MAE: \", mae)\n",
    "    print(\"RMSLE: \", rmsle)\n",
    "\n",
    "    # Output results\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07b5d9c2-795e-4cc9-86e3-adf62a1358d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def adv_grid_search(x_train, y_train, x_test, y_test, ml_pipeline, params, cv=3, include_probas=False, is_regression=False):\n",
    "    ''' \n",
    "    This helper function performs grid search on a machine learning pipeline with feature engineering \n",
    "    and outputs the RMSE for regression or a classification report for classification tasks.\n",
    "    '''\n",
    "    \n",
    "    # GridSearchCV to find the best model within the pipeline\n",
    "    model_grid_search = GridSearchCV(ml_pipeline, param_grid=params, cv=cv, error_score=-1)\n",
    "    start_time = time.time()  # capture the start time\n",
    "\n",
    "    # Fit the grid search to the training data\n",
    "    model_grid_search.fit(x_train, y_train)\n",
    "\n",
    "    # Retrieve the best model from grid search\n",
    "    best_model = model_grid_search.best_estimator_\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_preds = best_model.predict(x_test)\n",
    "    \n",
    "    # Evaluate based on regression or classification\n",
    "    if is_regression:\n",
    "        rmse = np.sqrt(mean_squared_error(y_true=y_test, y_pred=y_preds))\n",
    "        print(f'RMSE: {rmse:.5f}')\n",
    "    else:\n",
    "        print(classification_report(y_true=y_test, y_pred=y_preds))\n",
    "    \n",
    "    print(f'Best params: {model_grid_search.best_params_}')\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Overall took {(end_time - start_time):.2f} seconds\")\n",
    "    \n",
    "    # Optionally, include probabilities for classification tasks\n",
    "    if include_probas and not is_regression:\n",
    "        y_probas = best_model.predict_proba(x_test).max(axis=1)\n",
    "        return best_model, y_preds, y_probas\n",
    "    \n",
    "    return best_model, y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5d6dad-5663-4ddf-9e74-6f17a3309314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_grid_search(x_train, y_train, feature_engineering_pipeline=None):\n",
    "    # Parámetros iniciales para el GridSearch\n",
    "    params = {\n",
    "        'max_depth': [10, None],\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'num_leaves': [20, 31, 50],\n",
    "        'feature_fraction': [0.8, 0.9, 1.0],\n",
    "        'bagging_fraction': [0.8, 0.9, 1.0],\n",
    "        'min_child_samples': [10, 20, 30],\n",
    "        'lambda_l1': [0, 0.1, 0.5],\n",
    "        'lambda_l2': [0, 0.1, 0.5],\n",
    "        'max_bin': [255, 500, 1000],\n",
    "        'objective': ['regression']\n",
    "    }\n",
    "\n",
    "    base_model = LGBMRegressor(n_jobs=-1, verbose=-1)\n",
    "\n",
    "    model_grid_search = GridSearchCV(\n",
    "        base_model,\n",
    "        param_grid=params,\n",
    "        cv=3,\n",
    "        verbose=0,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    if feature_engineering_pipeline:\n",
    "        parsed_x_train = feature_engineering_pipeline.fit_transform(x_train, y_train)\n",
    "    else:\n",
    "        parsed_x_train = x_train\n",
    "\n",
    "    model_grid_search.fit(parsed_x_train, y_train)\n",
    "    best_params = model_grid_search.best_params_\n",
    "    \n",
    "    print(\"Best parameters from GridSearchCV:\", best_params)\n",
    "    \n",
    "    return best_params\n",
    "\n",
    "def fine_tuning_optuna(x_train, y_train, x_test, y_test, best_params, feature_engineering_pipeline=None, n_trials=33):\n",
    "    # Definir la función objetivo de Optuna, con un rango ajustado en torno a los mejores parámetros\n",
    "    def objective(trial):\n",
    "        max_depth = trial.suggest_int('max_depth', max(1, best_params['max_depth'] - 3 if best_params['max_depth'] else 1), best_params['max_depth'] + 3 if best_params['max_depth'] else 15)\n",
    "        n_estimators = trial.suggest_int('n_estimators', max(50, best_params['n_estimators'] - 50), best_params['n_estimators'] + 50, step=10)\n",
    "        learning_rate = trial.suggest_loguniform('learning_rate', best_params['learning_rate'] * 0.1, best_params['learning_rate'] * 10)\n",
    "        num_leaves = trial.suggest_int('num_leaves', max(20, best_params['num_leaves'] - 10), best_params['num_leaves'] + 10)\n",
    "        feature_fraction = trial.suggest_uniform('feature_fraction', 0.7, 1.0)\n",
    "        bagging_fraction = trial.suggest_uniform('bagging_fraction', 0.7, 1.0)\n",
    "        min_child_samples = trial.suggest_int('min_child_samples', max(5, best_params['min_child_samples'] - 5), best_params['min_child_samples'] + 5)\n",
    "        lambda_l1 = trial.suggest_loguniform('lambda_l1', 1e-8, 10.0)\n",
    "        lambda_l2 = trial.suggest_loguniform('lambda_l2', 1e-8, 10.0)\n",
    "        max_bin = trial.suggest_int('max_bin', max(50, best_params['max_bin'] - 200), best_params['max_bin'] + 200)\n",
    "        \n",
    "        model = LGBMRegressor(\n",
    "            max_depth=max_depth,\n",
    "            n_estimators=n_estimators,\n",
    "            learning_rate=learning_rate,\n",
    "            num_leaves=num_leaves,\n",
    "            feature_fraction=feature_fraction,\n",
    "            bagging_fraction=bagging_fraction,\n",
    "            min_child_samples=min_child_samples,\n",
    "            lambda_l1=lambda_l1,\n",
    "            lambda_l2=lambda_l2,\n",
    "            max_bin=max_bin,\n",
    "            objective='regression',\n",
    "            n_jobs=-1,\n",
    "            verbose=-1\n",
    "        )\n",
    "        \n",
    "        if feature_engineering_pipeline:\n",
    "            parsed_x_train = feature_engineering_pipeline.fit_transform(x_train, y_train)\n",
    "            parsed_x_test = feature_engineering_pipeline.transform(x_test)\n",
    "        else:\n",
    "            parsed_x_train = x_train\n",
    "            parsed_x_test = x_test\n",
    "        \n",
    "        model.fit(parsed_x_train, y_train)\n",
    "        y_pred = model.predict(parsed_x_test)\n",
    "        \n",
    "        rmsle = np.sqrt(mean_squared_log_error(y_test, y_pred))\n",
    "        \n",
    "        return rmsle  # Minimizar el RMSLE\n",
    "\n",
    "    # Crear el estudio de Optuna\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    \n",
    "    print(\"Best trial with Optuna:\")\n",
    "    trial = study.best_trial\n",
    "    print(\"  Value: \", trial.value)\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "    \n",
    "    return study.best_trial\n",
    "\n",
    "# Ejemplo de uso\n",
    "best_params = initial_grid_search(x_train, y_train, feature_engineering_pipeline)\n",
    "best_trial = fine_tuning_optuna(x_train, y_train, x_test, y_test, best_params, feature_engineering_pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
